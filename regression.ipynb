{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# comment out this cell if not running on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# copy zip to local directory\n",
        "print(\"Copying dataset from Google Drive...\")\n",
        "!cp \"/content/drive/My Drive/datasets/top50images.zip\" .\n",
        "\n",
        "print(\"Unzipping dataset...\")\n",
        "!unzip -q top50images.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM6mspi0b2DS",
        "outputId": "7e907f28-d19c-49eb-af62-f19da7e1400c"
      },
      "id": "XM6mspi0b2DS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Copying dataset from Google Drive...\n",
            "Unzipping dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "371ea0d1",
      "metadata": {
        "id": "371ea0d1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler, Dataset\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0f7a077",
      "metadata": {
        "id": "b0f7a077"
      },
      "outputs": [],
      "source": [
        "# paths to dataset and csv\n",
        "CSV_PATH = 'top50.csv'\n",
        "IMAGE_FOLDER_PATH = 'top50images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f760fd",
      "metadata": {
        "id": "35f760fd"
      },
      "outputs": [],
      "source": [
        "class CityImageDataset(Dataset):\n",
        "    \"\"\"Custom PyTorch Dataset for city image coordinate regression.\"\"\"\n",
        "    def __init__(self, csv_path, image_folder, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_path (str): Path to the csv file with annotations.\n",
        "            image_folder (str): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.img_labels = pd.read_csv(csv_path)\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "        # For regression, we don't need class-to-index mapping.\n",
        "        print(\"Dataset initialized for regression.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Fetches a data sample for a given index.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, coordinates) where coordinates is a tensor of [lat, lon].\n",
        "        \"\"\"\n",
        "        # 1. Get the image filename and coordinate labels from the dataframe\n",
        "        row = self.img_labels.iloc[idx]\n",
        "        image_filename = row['filename']\n",
        "        lat = row['lat']\n",
        "        lon = row['lon']\n",
        "\n",
        "        # 2. Construct the full image path\n",
        "        image_path = os.path.join(self.image_folder, image_filename)\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        # 3. Create the label tensor for regression\n",
        "        coordinates = torch.tensor([lat, lon], dtype=torch.float32)\n",
        "\n",
        "        # 4. Apply transformations if they exist\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3735ef4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3735ef4e",
        "outputId": "921f22cb-20a5-4771-a221-f76489385768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating dataset...\n",
            "Dataset initialized for regression.\n"
          ]
        }
      ],
      "source": [
        "# transform data for resnet\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),      # resize to 224 x 224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(               # normalize to imagenet stats\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# create dataset\n",
        "print(\"Creating dataset...\")\n",
        "full_dataset = CityImageDataset(\n",
        "    csv_path=CSV_PATH,\n",
        "    image_folder=IMAGE_FOLDER_PATH,\n",
        "    transform=data_transforms\n",
        ")\n",
        "\n",
        "# split data into 80/20 for train/val\n",
        "dataset_size = len(full_dataset)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "val_size = dataset_size - train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a276cd0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a276cd0e",
        "outputId": "ac6b52f8-6911-4e72-9df1-fe84a4fb52d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 8023\n",
            "Training samples: 6418\n",
            "Validation samples: 1605\n"
          ]
        }
      ],
      "source": [
        "# seed and split\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
        "\n",
        "print(f\"Total samples: {dataset_size}\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78203e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f78203e1",
        "outputId": "e634a0f0-9ce8-470b-e381-aed332464ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# create data loaders\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2) # change this to 0 if running locally (not colab)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2) # change this to 0 if running locally (not colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f39d1914",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f39d1914",
        "outputId": "36d5d846-1c10-4ce5-c97a-174981ba1eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# get device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bdfb051",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bdfb051",
        "outputId": "46c9ddbc-c5d9-40a6-c48f-a02bcbcf2827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freezing parameters of pre-trained layers...\n",
            "Replaced final layer for regression. Output features: 2\n"
          ]
        }
      ],
      "source": [
        "# load resnet model\n",
        "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "# model = models.resnet50(weights='DEFAULT')\n",
        "\n",
        "# freeze params/layers of model\n",
        "print(\"Freezing parameters of pre-trained layers...\")\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# replace the final layer for regression. output is 2 for lat and lon\n",
        "num_ftrs = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(num_ftrs, 2)\n",
        "print(f\"Replaced final layer for regression. Output features: 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d4586d",
      "metadata": {
        "id": "01d4586d"
      },
      "outputs": [],
      "source": [
        "# move model to device\n",
        "resnet50 = resnet50.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc3f77d8",
      "metadata": {
        "id": "cc3f77d8"
      },
      "outputs": [],
      "source": [
        "# hyperparams\n",
        "NUM_EPOCHS = 60\n",
        "LEARNING_RATE = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7666ee",
      "metadata": {
        "id": "cc7666ee"
      },
      "outputs": [],
      "source": [
        "# set up loss func and optimizer\n",
        "\n",
        "# loss func\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "# will only update weights for final layer since we froze previous ones\n",
        "optimizer = optim.Adam(resnet50.fc.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f8c83b",
      "metadata": {
        "id": "88f8c83b"
      },
      "outputs": [],
      "source": [
        "def train_and_validate(model, loss_func, optimizer, train_loader, val_loader, device, num_epochs=5):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        model: model to train\n",
        "        loss_func: loss function\n",
        "        optimizer: optimizer\n",
        "        train_loader: DataLoader for the training set\n",
        "        val_loader: DataLoader for the validation set\n",
        "        device: the torch.device to run on\n",
        "        num_epochs: number of epochs\n",
        "    \"\"\"\n",
        "    print()\n",
        "    print(\"--- Starting Training ---\")\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # keep track of how much time each epoch takes\n",
        "        start_time = time.time()\n",
        "\n",
        "        # TRAINING\n",
        "        model.train()  # set to training mode\n",
        "        running_loss = 0.0  # keep track of loss\n",
        "\n",
        "        # iterate through batches\n",
        "        for images, labels in train_loader:\n",
        "\n",
        "            # move to device\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # zero out gradients from previous batch\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # apply loss function\n",
        "            loss = loss_func(outputs, labels)\n",
        "\n",
        "            # backprop\n",
        "            loss.backward()\n",
        "\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # keep track of loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # keep track of total epoch loss\n",
        "        epoch_train_loss = running_loss / len(train_loader.sampler)\n",
        "\n",
        "        # VALIDATION\n",
        "        model.eval()  # set to eval mode\n",
        "        val_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "\n",
        "        # no gradients\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # apply forward pass and evaluate output\n",
        "                outputs = model(images)\n",
        "                loss = loss_func(outputs, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # keep track of total epoch val loss\n",
        "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "        # time it took for epoch to train\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} | Time: {epoch_time:.2f}s\")\n",
        "        print(f\"\\t Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f}\")\n",
        "\n",
        "    print()\n",
        "    print(\"--- Training Complete ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f823a2e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f823a2e9",
        "outputId": "22befa30-e25c-4a7c-8178-957f75d6c548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Training ---\n",
            "Epoch 1/60 | Time: 44.00s\n",
            "\t Train Loss: 3435.3758 | Val Loss: 1967.1636\n",
            "Epoch 2/60 | Time: 44.19s\n",
            "\t Train Loss: 1196.3921 | Val Loss: 874.5019\n",
            "Epoch 3/60 | Time: 42.59s\n",
            "\t Train Loss: 518.3372 | Val Loss: 451.5892\n",
            "Epoch 4/60 | Time: 43.07s\n",
            "\t Train Loss: 366.2274 | Val Loss: 338.5996\n",
            "Epoch 5/60 | Time: 42.59s\n",
            "\t Train Loss: 335.5985 | Val Loss: 312.4147\n",
            "Epoch 6/60 | Time: 42.42s\n",
            "\t Train Loss: 325.2496 | Val Loss: 317.7475\n",
            "Epoch 7/60 | Time: 42.77s\n",
            "\t Train Loss: 309.1009 | Val Loss: 297.3292\n",
            "Epoch 8/60 | Time: 42.64s\n",
            "\t Train Loss: 306.8656 | Val Loss: 305.2011\n",
            "Epoch 9/60 | Time: 42.60s\n",
            "\t Train Loss: 298.8620 | Val Loss: 276.6658\n",
            "Epoch 10/60 | Time: 42.52s\n",
            "\t Train Loss: 290.1457 | Val Loss: 272.0964\n",
            "Epoch 11/60 | Time: 42.72s\n",
            "\t Train Loss: 273.1789 | Val Loss: 267.3201\n",
            "Epoch 12/60 | Time: 42.77s\n",
            "\t Train Loss: 273.7532 | Val Loss: 263.5162\n",
            "Epoch 13/60 | Time: 42.99s\n",
            "\t Train Loss: 265.9641 | Val Loss: 257.4835\n",
            "Epoch 14/60 | Time: 43.18s\n",
            "\t Train Loss: 257.4150 | Val Loss: 248.1742\n",
            "Epoch 15/60 | Time: 42.92s\n",
            "\t Train Loss: 249.9022 | Val Loss: 246.6748\n",
            "Epoch 16/60 | Time: 43.49s\n",
            "\t Train Loss: 249.1971 | Val Loss: 258.5792\n",
            "Epoch 17/60 | Time: 43.66s\n",
            "\t Train Loss: 243.4445 | Val Loss: 244.2865\n",
            "Epoch 18/60 | Time: 43.74s\n",
            "\t Train Loss: 234.6058 | Val Loss: 230.3819\n",
            "Epoch 19/60 | Time: 43.25s\n",
            "\t Train Loss: 232.8695 | Val Loss: 225.3836\n",
            "Epoch 20/60 | Time: 42.88s\n",
            "\t Train Loss: 226.6339 | Val Loss: 220.6066\n",
            "Epoch 21/60 | Time: 42.52s\n",
            "\t Train Loss: 219.0096 | Val Loss: 223.8359\n",
            "Epoch 22/60 | Time: 42.61s\n",
            "\t Train Loss: 217.8381 | Val Loss: 217.9048\n",
            "Epoch 23/60 | Time: 42.57s\n",
            "\t Train Loss: 209.5956 | Val Loss: 216.2779\n",
            "Epoch 24/60 | Time: 42.98s\n",
            "\t Train Loss: 206.5770 | Val Loss: 210.6333\n",
            "Epoch 25/60 | Time: 42.32s\n",
            "\t Train Loss: 203.4308 | Val Loss: 208.5687\n",
            "Epoch 26/60 | Time: 42.70s\n",
            "\t Train Loss: 201.6012 | Val Loss: 207.7472\n",
            "Epoch 27/60 | Time: 43.01s\n",
            "\t Train Loss: 199.7480 | Val Loss: 202.2208\n",
            "Epoch 28/60 | Time: 42.58s\n",
            "\t Train Loss: 197.9698 | Val Loss: 212.3949\n",
            "Epoch 29/60 | Time: 42.00s\n",
            "\t Train Loss: 192.6947 | Val Loss: 202.5450\n",
            "Epoch 30/60 | Time: 42.54s\n",
            "\t Train Loss: 190.6640 | Val Loss: 202.7761\n",
            "Epoch 31/60 | Time: 42.46s\n",
            "\t Train Loss: 186.4895 | Val Loss: 194.0509\n",
            "Epoch 32/60 | Time: 42.87s\n",
            "\t Train Loss: 187.0362 | Val Loss: 193.7160\n",
            "Epoch 33/60 | Time: 43.15s\n",
            "\t Train Loss: 179.9695 | Val Loss: 193.8890\n",
            "Epoch 34/60 | Time: 43.87s\n",
            "\t Train Loss: 180.9153 | Val Loss: 193.4415\n",
            "Epoch 35/60 | Time: 44.21s\n",
            "\t Train Loss: 176.2423 | Val Loss: 191.9749\n",
            "Epoch 36/60 | Time: 42.74s\n",
            "\t Train Loss: 176.4518 | Val Loss: 188.5550\n",
            "Epoch 37/60 | Time: 43.00s\n",
            "\t Train Loss: 175.1528 | Val Loss: 185.5869\n",
            "Epoch 38/60 | Time: 44.32s\n",
            "\t Train Loss: 170.0210 | Val Loss: 188.2923\n",
            "Epoch 39/60 | Time: 42.73s\n",
            "\t Train Loss: 172.9848 | Val Loss: 190.6229\n",
            "Epoch 40/60 | Time: 42.44s\n",
            "\t Train Loss: 165.2481 | Val Loss: 181.8752\n",
            "Epoch 41/60 | Time: 44.46s\n",
            "\t Train Loss: 171.6007 | Val Loss: 195.2496\n",
            "Epoch 42/60 | Time: 44.21s\n",
            "\t Train Loss: 169.9812 | Val Loss: 180.3747\n",
            "Epoch 43/60 | Time: 43.16s\n",
            "\t Train Loss: 163.8982 | Val Loss: 184.7925\n",
            "Epoch 44/60 | Time: 45.12s\n",
            "\t Train Loss: 162.3506 | Val Loss: 178.5508\n",
            "Epoch 45/60 | Time: 42.93s\n",
            "\t Train Loss: 162.2778 | Val Loss: 180.4169\n",
            "Epoch 46/60 | Time: 42.83s\n",
            "\t Train Loss: 160.2674 | Val Loss: 177.7327\n",
            "Epoch 47/60 | Time: 42.84s\n",
            "\t Train Loss: 160.6646 | Val Loss: 174.8604\n",
            "Epoch 48/60 | Time: 45.63s\n",
            "\t Train Loss: 154.2337 | Val Loss: 179.5932\n",
            "Epoch 49/60 | Time: 42.61s\n",
            "\t Train Loss: 156.3259 | Val Loss: 193.1016\n",
            "Epoch 50/60 | Time: 42.26s\n",
            "\t Train Loss: 155.0227 | Val Loss: 173.0665\n",
            "Epoch 51/60 | Time: 44.91s\n",
            "\t Train Loss: 156.9886 | Val Loss: 175.3542\n",
            "Epoch 52/60 | Time: 42.20s\n",
            "\t Train Loss: 157.5791 | Val Loss: 173.6359\n",
            "Epoch 53/60 | Time: 42.60s\n",
            "\t Train Loss: 154.4936 | Val Loss: 172.7473\n",
            "Epoch 54/60 | Time: 44.88s\n",
            "\t Train Loss: 151.9312 | Val Loss: 175.2835\n",
            "Epoch 55/60 | Time: 42.95s\n",
            "\t Train Loss: 151.7344 | Val Loss: 179.1439\n",
            "Epoch 56/60 | Time: 42.43s\n",
            "\t Train Loss: 148.9095 | Val Loss: 173.0782\n",
            "Epoch 57/60 | Time: 43.39s\n",
            "\t Train Loss: 150.3910 | Val Loss: 171.1948\n",
            "Epoch 58/60 | Time: 43.28s\n",
            "\t Train Loss: 148.9218 | Val Loss: 168.1417\n",
            "Epoch 59/60 | Time: 43.29s\n",
            "\t Train Loss: 147.2358 | Val Loss: 170.3907\n",
            "Epoch 60/60 | Time: 42.66s\n",
            "\t Train Loss: 148.1556 | Val Loss: 170.4782\n",
            "\n",
            "--- Training Complete ---\n"
          ]
        }
      ],
      "source": [
        "train_and_validate(resnet50, loss_func, optimizer, train_loader, val_loader, device, NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one degree of latitude -> roughly 69 miles (111 km)\n",
        "#"
      ],
      "metadata": {
        "id": "_gPMbLvhcShd"
      },
      "id": "_gPMbLvhcShd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Starting Training ---\n",
        "# Epoch 1/60 | Time: 44.00s\n",
        "# \t Train Loss: 3435.3758 | Val Loss: 1967.1636\n",
        "# Epoch 2/60 | Time: 44.19s\n",
        "# \t Train Loss: 1196.3921 | Val Loss: 874.5019\n",
        "# Epoch 3/60 | Time: 42.59s\n",
        "# \t Train Loss: 518.3372 | Val Loss: 451.5892\n",
        "# Epoch 4/60 | Time: 43.07s\n",
        "# \t Train Loss: 366.2274 | Val Loss: 338.5996\n",
        "# Epoch 5/60 | Time: 42.59s\n",
        "# \t Train Loss: 335.5985 | Val Loss: 312.4147\n",
        "# Epoch 6/60 | Time: 42.42s\n",
        "# \t Train Loss: 325.2496 | Val Loss: 317.7475\n",
        "# Epoch 7/60 | Time: 42.77s\n",
        "# \t Train Loss: 309.1009 | Val Loss: 297.3292\n",
        "# Epoch 8/60 | Time: 42.64s\n",
        "# \t Train Loss: 306.8656 | Val Loss: 305.2011\n",
        "# Epoch 9/60 | Time: 42.60s\n",
        "# \t Train Loss: 298.8620 | Val Loss: 276.6658\n",
        "# Epoch 10/60 | Time: 42.52s\n",
        "# \t Train Loss: 290.1457 | Val Loss: 272.0964\n",
        "# Epoch 11/60 | Time: 42.72s\n",
        "# \t Train Loss: 273.1789 | Val Loss: 267.3201\n",
        "# Epoch 12/60 | Time: 42.77s\n",
        "# \t Train Loss: 273.7532 | Val Loss: 263.5162\n",
        "# Epoch 13/60 | Time: 42.99s\n",
        "# \t Train Loss: 265.9641 | Val Loss: 257.4835\n",
        "# Epoch 14/60 | Time: 43.18s\n",
        "# \t Train Loss: 257.4150 | Val Loss: 248.1742\n",
        "# Epoch 15/60 | Time: 42.92s\n",
        "# \t Train Loss: 249.9022 | Val Loss: 246.6748\n",
        "# Epoch 16/60 | Time: 43.49s\n",
        "# \t Train Loss: 249.1971 | Val Loss: 258.5792\n",
        "# Epoch 17/60 | Time: 43.66s\n",
        "# \t Train Loss: 243.4445 | Val Loss: 244.2865\n",
        "# Epoch 18/60 | Time: 43.74s\n",
        "# \t Train Loss: 234.6058 | Val Loss: 230.3819\n",
        "# Epoch 19/60 | Time: 43.25s\n",
        "# \t Train Loss: 232.8695 | Val Loss: 225.3836\n",
        "# Epoch 20/60 | Time: 42.88s\n",
        "# \t Train Loss: 226.6339 | Val Loss: 220.6066\n",
        "# Epoch 21/60 | Time: 42.52s\n",
        "# \t Train Loss: 219.0096 | Val Loss: 223.8359\n",
        "# Epoch 22/60 | Time: 42.61s\n",
        "# \t Train Loss: 217.8381 | Val Loss: 217.9048\n",
        "# Epoch 23/60 | Time: 42.57s\n",
        "# \t Train Loss: 209.5956 | Val Loss: 216.2779\n",
        "# Epoch 24/60 | Time: 42.98s\n",
        "# \t Train Loss: 206.5770 | Val Loss: 210.6333\n",
        "# Epoch 25/60 | Time: 42.32s\n",
        "# \t Train Loss: 203.4308 | Val Loss: 208.5687\n",
        "# Epoch 26/60 | Time: 42.70s\n",
        "# \t Train Loss: 201.6012 | Val Loss: 207.7472\n",
        "# Epoch 27/60 | Time: 43.01s\n",
        "# \t Train Loss: 199.7480 | Val Loss: 202.2208\n",
        "# Epoch 28/60 | Time: 42.58s\n",
        "# \t Train Loss: 197.9698 | Val Loss: 212.3949\n",
        "# Epoch 29/60 | Time: 42.00s\n",
        "# \t Train Loss: 192.6947 | Val Loss: 202.5450\n",
        "# Epoch 30/60 | Time: 42.54s\n",
        "# \t Train Loss: 190.6640 | Val Loss: 202.7761\n",
        "# Epoch 31/60 | Time: 42.46s\n",
        "# \t Train Loss: 186.4895 | Val Loss: 194.0509\n",
        "# Epoch 32/60 | Time: 42.87s\n",
        "# \t Train Loss: 187.0362 | Val Loss: 193.7160\n",
        "# Epoch 33/60 | Time: 43.15s\n",
        "# \t Train Loss: 179.9695 | Val Loss: 193.8890\n",
        "# Epoch 34/60 | Time: 43.87s\n",
        "# \t Train Loss: 180.9153 | Val Loss: 193.4415\n",
        "# Epoch 35/60 | Time: 44.21s\n",
        "# \t Train Loss: 176.2423 | Val Loss: 191.9749\n",
        "# Epoch 36/60 | Time: 42.74s\n",
        "# \t Train Loss: 176.4518 | Val Loss: 188.5550\n",
        "# Epoch 37/60 | Time: 43.00s\n",
        "# \t Train Loss: 175.1528 | Val Loss: 185.5869\n",
        "# Epoch 38/60 | Time: 44.32s\n",
        "# \t Train Loss: 170.0210 | Val Loss: 188.2923\n",
        "# Epoch 39/60 | Time: 42.73s\n",
        "# \t Train Loss: 172.9848 | Val Loss: 190.6229\n",
        "# Epoch 40/60 | Time: 42.44s\n",
        "# \t Train Loss: 165.2481 | Val Loss: 181.8752\n",
        "# Epoch 41/60 | Time: 44.46s\n",
        "# \t Train Loss: 171.6007 | Val Loss: 195.2496\n",
        "# Epoch 42/60 | Time: 44.21s\n",
        "# \t Train Loss: 169.9812 | Val Loss: 180.3747\n",
        "# Epoch 43/60 | Time: 43.16s\n",
        "# \t Train Loss: 163.8982 | Val Loss: 184.7925\n",
        "# Epoch 44/60 | Time: 45.12s\n",
        "# \t Train Loss: 162.3506 | Val Loss: 178.5508\n",
        "# Epoch 45/60 | Time: 42.93s\n",
        "# \t Train Loss: 162.2778 | Val Loss: 180.4169\n",
        "# Epoch 46/60 | Time: 42.83s\n",
        "# \t Train Loss: 160.2674 | Val Loss: 177.7327\n",
        "# Epoch 47/60 | Time: 42.84s\n",
        "# \t Train Loss: 160.6646 | Val Loss: 174.8604\n",
        "# Epoch 48/60 | Time: 45.63s\n",
        "# \t Train Loss: 154.2337 | Val Loss: 179.5932\n",
        "# Epoch 49/60 | Time: 42.61s\n",
        "# \t Train Loss: 156.3259 | Val Loss: 193.1016\n",
        "# Epoch 50/60 | Time: 42.26s\n",
        "# \t Train Loss: 155.0227 | Val Loss: 173.0665\n",
        "# Epoch 51/60 | Time: 44.91s\n",
        "# \t Train Loss: 156.9886 | Val Loss: 175.3542\n",
        "# Epoch 52/60 | Time: 42.20s\n",
        "# \t Train Loss: 157.5791 | Val Loss: 173.6359\n",
        "# Epoch 53/60 | Time: 42.60s\n",
        "# \t Train Loss: 154.4936 | Val Loss: 172.7473\n",
        "# Epoch 54/60 | Time: 44.88s\n",
        "# \t Train Loss: 151.9312 | Val Loss: 175.2835\n",
        "# Epoch 55/60 | Time: 42.95s\n",
        "# \t Train Loss: 151.7344 | Val Loss: 179.1439\n",
        "# Epoch 56/60 | Time: 42.43s\n",
        "# \t Train Loss: 148.9095 | Val Loss: 173.0782\n",
        "# Epoch 57/60 | Time: 43.39s\n",
        "# \t Train Loss: 150.3910 | Val Loss: 171.1948\n",
        "# Epoch 58/60 | Time: 43.28s\n",
        "# \t Train Loss: 148.9218 | Val Loss: 168.1417\n",
        "# Epoch 59/60 | Time: 43.29s\n",
        "# \t Train Loss: 147.2358 | Val Loss: 170.3907\n",
        "# Epoch 60/60 | Time: 42.66s\n",
        "# \t Train Loss: 148.1556 | Val Loss: 170.4782\n",
        "\n",
        "# --- Training Complete ---"
      ],
      "metadata": {
        "id": "-I0-LOEwp6mh"
      },
      "id": "-I0-LOEwp6mh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}